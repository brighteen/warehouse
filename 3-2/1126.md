

# **GAN 판별자를 활용한 밀도 비율 추정 기반 Score-based/Diffusion 모델의 잠재 공간 탐색 교정: 수학적 타당성 검증 및 실험적 보강 방안**

## **1\. 서론: 생성 모델링의 패러다임 통합과 난제**

현대 딥러닝 기반 생성 모델링(Generative Modeling)은 크게 두 가지 지배적인 패러다임으로 양분되어 발전해 왔습니다. 첫 번째는 생성적 적대 신경망(Generative Adversarial Networks, GAN)으로 대표되는 암시적 가능도(Implicit Likelihood) 모델로, 데이터 분포를 직접적으로 모델링하지 않고 판별자(Discriminator)와의 적대적 학습을 통해 고주파수(High-frequency) 세부 묘사가 뛰어난 샘플을 생성하는 데 탁월한 성능을 보였습니다.1 두 번째는 변분 오토인코더(VAE) 1와 최근 급부상한 스코어 기반 생성 모델(Score-based Generative Models, SGM) 1 및 잡음 제거 확산 확률 모델(Denoising Diffusion Probabilistic Models, DDPM) 1로 대표되는 명시적 가능도(Explicit Likelihood) 또는 그에 준하는 모델들입니다. 이들은 데이터 분포의 스코어 함수(Score Function)를 추정하거나 확산 과정의 역과정(Reverse Process)을 학습함으로써 전체 데이터 분포를 포괄하는 안정적인 학습과 샘플링을 가능하게 했습니다.1

그러나 각 방법론은 고유한 한계를 지니고 있습니다. GAN은 학습의 불안정성과 모드 붕괴(Mode Collapse)라는 고질적인 문제를 안고 있으며, 이는 전체 데이터 분포의 다양성을 충분히 포착하지 못하는 결과로 이어집니다.1 반면, 스코어 기반 모델 및 확산 모델은 학습 안정성과 분포 커버리지(Coverage) 측면에서는 우수하나, 샘플링 속도가 느리고 저밀도 영역(Low-density region)에서의 스코어 추정 오류로 인해 데이터 매니폴드(Data Manifold)를 벗어난 샘플이 생성될 위험이 있습니다.1 특히 고차원 데이터 공간에서 데이터가 존재하는 매니폴드의 차원은 상대적으로 매우 낮다는 '매니폴드 가설(Manifold Hypothesis)'은 스코어 매칭 기반 학습에 있어 스코어가 정의되지 않거나 불안정한 영역을 초래하는 주요 원인입니다.1

본 연구 보고서는 이러한 두 패러다임의 장점을 결합하여 상호 보완적인 하이브리드 알고리즘을 제안하고 그 타당성을 검증하는 데 목적이 있습니다. 구체적으로, GAN의 판별자를 단순한 분류기가 아닌 '밀도 비율 추정기(Density Ratio Estimator, DRE)'로 재해석하고 1, 이를 통해 얻어진 밀도 비율 정보를 스코어 기반 모델의 랑주뱅 역학(Langevin Dynamics) 샘플링 과정에 주입하여 잠재 공간(Latent Space) 탐색을 교정(Calibration)하는 알고리즘을 설계합니다. 이는 스코어 함수가 제공하는 국소적 벡터장(Local Vector Field) 정보에 판별자가 제공하는 전역적 에너지 차이(Global Energy Difference) 정보를 보정항으로 추가함으로써, 샘플링 궤적을 데이터 매니폴드로 더욱 강력하게 유도하는 수학적 기제를 마련하는 것입니다. 본 보고서에서는 이 접근법의 수학적 유도 과정을 엄밀히 검증하고1의 예측기-교정기(Predictor-Corrector) 프레임워크 및 1의 적대적 오토인코더(AAE) 개념을 도입하여 실험적 성능을 극대화할 수 있는 구체적인 방안을 제시합니다.

---

## **2\. 이론적 배경 및 수학적 기초**

제안하는 알고리즘의 타당성을 논하기 앞서, 구성 요소가 되는 GAN, 스코어 기반 모델, 그리고 이들을 연결하는 확률 미분 방정식(SDE)의 수학적 기초를 확립할 필요가 있습니다.

### **2.1 GAN 판별자의 밀도 비율 추정 특성**

Goodfellow et al. 1이 제안한 GAN의 목적 함수는 생성자 $G$와 판별자 $D$ 간의 미니맥스(Minimax) 게임으로 정의됩니다.

$$\\min\_G \\max\_D V(D, G) \= \\mathbb{E}\_{x \\sim p\_{data}(x)} \+ \\mathbb{E}\_{z \\sim p\_z(z)}$$

여기서 $p\_{data}(x)$는 실제 데이터 분포, $p\_g(x)$는 생성자가 유도하는 분포입니다. 이 이론의 핵심은 생성자 $G$가 고정되었을 때, 최적 판별자 $D^\*\_G(x)$가 닫힌 해(Closed-form solution)를 갖는다는 점입니다.

$$D^\*\_G(x) \= \\frac{p\_{data}(x)}{p\_{data}(x) \+ p\_g(x)}$$

이 식을 대수적으로 변형하면, 최적 판별자의 출력값이 실제 데이터 분포와 모델 분포 간의 비율(Density Ratio)을 내포하고 있음을 알 수 있습니다.

$$\\frac{D^\*\_G(x)}{1 \- D^\*\_G(x)} \= \\frac{\\frac{p*{data}(x)}{p\_{data}(x) \+ p\_g(x)}}{\\frac{p\_g(x)}{p\_{data}(x) \+ p\_g(x)}} \= \\frac{p\_{data}(x)}{p\_g(x)} \= r(x)$$

여기서 $r(x)$는 데이터 밀도와 모델 밀도의 비율을 나타냅니다. 이는 판별자가 단순한 분류 경계면을 학습하는 것을 넘어, 현재 모델 $p\_g$가 실제 데이터 $p\_{data}$에 비해 얼마나 '에너지'가 높은지(즉, 확률이 낮은지)를 측정하는 추정기임을 시사합니다. 이 비율 정보는 스코어 기반 모델이 놓칠 수 있는 전역적인 분포 불일치 정보를 제공하는 핵심 단서가 됩니다.1

### **2.2 스코어 기반 생성 모델과 랑주뱅 역학**

스코어 기반 모델은 데이터 분포의 로그 밀도 함수의 기울기, 즉 스코어 함수 $\\nabla\_x \\log p\_{data}(x)$를 신경망 $s\_\\theta(x)$로 근사하는 방식입니다.1 학습된 스코어 함수를 이용하여 샘플을 생성하기 위해 랑주뱅 역학(Langevin Dynamics)을 사용합니다.

$$ x\_{i+1} \= x\_i \+ \\frac{\\epsilon}{2} \\nabla\_x \\log p(x\_i) \+ \\sqrt{\\epsilon} z\_i, \\quad z\_i \\sim \\mathcal{N}(0, I) $$

이 과정은 임의의 초기 상태에서 시작하여 점진적으로 확률 밀도가 높은 영역(데이터 매니폴드)으로 이동하는 과정입니다. Song & Ermon 1은 데이터에 여러 단계의 잡음 $\\sigma\_1 \> \\sigma\_2 \> \\dots \> \\sigma\_L$을 주입하고, 각 잡음 레벨에 해당하는 스코어 네트워크(Noise Conditional Score Network, NCSN)를 학습시키는 방법을 제안했습니다. 이는 데이터가 저차원 매니폴드에 존재할 때 발생하는 스코어 정의의 어려움을 해결하고, 저밀도 영역에서의 스코어 추정 정확도를 높여줍니다.1

### **2.3 확률 미분 방정식(SDE)을 통한 통합**

Song et al. 1은 확산 모델과 스코어 기반 모델을 확률 미분 방정식(Stochastic Differential Equation, SDE)의 프레임워크로 통합하였습니다. 데이터 $x(0)$에서 잡음 $x(T)$로 가는 순방향 과정(Forward Process)은 다음과 같은 Itô SDE로 표현됩니다.

$$dx \= f(x, t)dt \+ g(t)dw$$  

이에 상응하는 역방향 과정(Reverse Process) 역시 SDE로 기술되며, 이를 통해 잡음에서 데이터를 생성할 수 있습니다.

$$dx \= \[f(x, t) \- g(t)^2 \\nabla\_x \\log p\_t(x)\]dt \+ g(t)d\\bar{w}$$  

여기서 $\\nabla\_x \\log p\_t(x)$는 시간 $t$에서의 주변 확률 분포의 스코어 함수입니다. 이 수식은 생성 과정이 스코어 함수의 정확도에 전적으로 의존함을 보여주며, 본 연구에서 제안하는 '교정' 알고리즘이 개입할 수 있는 수학적 지점을 명확히 해줍니다.1

---

## **3\. 제안 알고리즘의 수학적 타당성 검증**

본 연구의 핵심 제안은 GAN 판별자로부터 추출한 밀도 비율 정보를 사용하여 스코어 기반 모델의 추정 오차를 보정하는 것입니다. 이 섹션에서는 이 아이디어의 수학적 타당성을 엄밀하게 유도합니다.

### **3.1 스코어 보정항의 유도**

우리의 목표는 실제 데이터 분포 $p\_{data}(x)$로부터 샘플링하는 것입니다. 하지만 우리가 가진 것은 근사된 모델 분포 $p\_g(x)$ (또는 $p\_\\theta$)의 스코어 함수 $s\_\\theta(x) \\approx \\nabla\_x \\log p\_g(x)$입니다. 실제 데이터 분포의 스코어는 모델 분포와 밀도 비율 $r(x) \= p\_{data}(x) / p\_g(x)$을 사용하여 다음과 같이 분해할 수 있습니다.

$$\\nabla\_x \\log p\_{data}(x) \= \\nabla\_x \\log \\left( p\_g(x) \\cdot \\frac{p\_{data}(x)}{p\_g(x)} \\right)$$

$$= \\nabla\_x \\log p\_g(x) \+ \\nabla\_x \\log \\left( \\frac{p\_{data}(x)}{p\_g(x)} \\right)$$  

여기서 첫 번째 항 $\\nabla\_x \\log p\_g(x)$는 확산 모델이 학습한 스코어 네트워크 $s\_\\theta(x)$에 해당합니다. 두 번째 항은 모델 분포와 실제 분포 간의 차이를 보정해 주는 '잔여 스코어(Residual Score)' 또는 '교정항(Correction Term)'으로 해석될 수 있습니다.

앞서 2.1절에서 유도한 판별자의 성질을 이용하면, 이 교정항을 판별자 $D(x)$로 표현할 수 있습니다. $r(x) \\approx \\frac{D(x)}{1 \- D(x)}$ 이므로,

$$\\nabla\_x \\log r(x) \\approx \\nabla\_x \\log \\left( \\frac{D(x)}{1 \- D(x)} \\right)$$

$$= \\nabla\_x$$

$$= \\frac{1}{D(x)}\\nabla\_x D(x) \- \\frac{1}{1 \- D(x)}(-\\nabla\_x D(x))$$

$$= \\left( \\frac{1}{D(x)} \+ \\frac{1}{1 \- D(x)} \\right) \\nabla\_x D(x)$$

$$= \\frac{1}{D(x)(1 \- D(x))} \\nabla\_x D(x)$$  

이 유도 과정은 수학적으로 매우 중요한 함의를 갖습니다.

1. **교정의 방향성:** 판별자의 그래디언트 $\\nabla\_x D(x)$는 샘플 $x$를 $p\_{data}$가 더 높은 영역(판별자가 '진짜'라고 판단하는 방향)으로 밀어줍니다.  
2. **가중치 조절:** 계수 $\\frac{1}{D(x)(1 \- D(x))}$는 판별자가 확신을 가지지 못하는 영역(즉, $D(x) \\approx 0.5$가 아닌 영역, 특히 $D(x)$가 0이나 1에 가까운 영역)에서 그래디언트의 크기를 조절합니다. 다만 실제 구현에서는 수치적 안정성을 위해 로짓(logit) 스케일에서의 그래디언트 $\\nabla\_x \\text{logit}(D(x))$를 사용하는 것이 일반적입니다.

따라서, 수정된 랑주뱅 역학의 업데이트 규칙은 다음과 같이 정의됩니다.

$$ x\_{t+1} \= x\_t \+ \\frac{\\epsilon}{2} \\left( s\_\\theta(x\_t) \+ \\lambda \\nabla\_x \\log \\frac{D(x\_t)}{1 \- D(x\_t)} \\right) \+ \\sqrt{\\epsilon} z\_t $$

여기서 $\\lambda$는 판별자 기반 교정의 강도를 조절하는 하이퍼파라미터입니다. 이 식은 스코어 매칭이 놓친 전역적인 분포 불일치를 판별자의 그래디언트를 통해 국소적으로 수정하여, 샘플링 궤적을 $p\_{data}$의 매니폴드로 강력하게 견인하는 수학적 근거를 제공합니다.

### **3.2 잠재 공간(Latent Space)에서의 교정 타당성**

사용자 질의는 특히 "잠재 공간 탐색의 교정"을 언급했습니다. 확산 모델에서의 잠재 변수 $x\_T$는 일반적으로 표준 정규분포 $\\mathcal{N}(0, I)$를 따르도록 설계되지만, 유한한 시간 $T$와 모델의 불완전성으로 인해 실제 역과정의 시작점 분포와 차이가 발생할 수 있습니다. 또한, VAE와 같은 모델에서는 사전 분포 $p(z)$와 집계된 사후 분포(Aggregated Posterior) $q(z) \= \\int q(z|x)p\_{data}(x)dx$ 간의 불일치가 발생합니다.1

Adversarial Autoencoders (AAE) 1는 잠재 공간의 분포를 사전 분포에 강제로 맞추기 위해 판별자를 사용합니다. 본 연구의 제안은 이 개념을 확산 모델의 샘플링 과정에 적용하는 것으로 확장할 수 있습니다. 만약 우리가 잠재 공간 $z$ (확산 모델에서는 $x\_T$ 근방)에서 샘플링을 수행한다면, 판별자 $D\_z$는 현재 샘플이 사전 분포 $p(z)$에서 왔는지, 아니면 데이터로부터 인코딩된(또는 역확산된) 분포 $q(z)$에서 왔는지를 구분합니다.

이때의 교정항 $\\nabla\_z \\log \\frac{D\_z(z)}{1 \- D\_z(z)}$는 샘플링 궤적이 단순히 가우시안 노이즈에 머무르는 것이 아니라, 실제 데이터가 맵핑되는 유의미한 잠재 매니폴드 영역으로 이동하도록 강제합니다. 이는 1에서 보여준 바와 같이, 잠재 공간 내의 '구멍(holes)'을 피하고 데이터가 조밀하게 분포한 영역을 탐색하도록 유도하여 생성 샘플의 품질을 높이는 데 기여합니다.

---

## **4\. 알고리즘 구현 및 실험적 보강 방안**

이론적 타당성을 바탕으로, 실제 알고리즘 구현을 위한 구체적인 프레임워크와 실험적 성능을 극대화하기 위한 보강 방안을 1와 1의 연구 결과를 토대로 제안합니다.

### **4.1 예측기-교정기(Predictor-Corrector) 프레임워크 내 통합**

Song et al. 1은 SDE를 풀기 위해 수치적 솔버(Predictor)와 MCMC 단계(Corrector)를 결합한 PC 샘플러를 제안했습니다. 제안하는 밀도 비율 교정 알고리즘은 이 프레임워크의 **Corrector** 단계에 통합되는 것이 가장 적합합니다.

**표 1: 제안하는 DRE-LD (Density-Ratio Enhanced Langevin Diffusion) 알고리즘 구조**

| 단계 | 기존 PC 샘플러 | 제안하는 DRE-LD 샘플러 |
| :---- | :---- | :---- |
| **입력** | 현재 시점의 샘플 $x\_t$ | 현재 시점의 샘플 $x\_t$ |
| **Predictor (예측)** | 역방향 확산 SDE를 풀어 $x\_{t-1}$ 예측 (예: Euler-Maruyama) | 기존과 동일하게 $s\_\\theta(x\_t, t)$를 사용하여 $x\_{t-1}$ 예측 |
| **Corrector (교정)** | 랑주뱅 역학을 사용하여 $p\_{t-1}(x)$ 분포로 수렴 유도 | **판별자 교정 추가:** $s\_\\theta$에 $\\lambda \\nabla \\mathcal{R}(x)$를 더해 업데이트 |
| **교정 수식** | $x' \\leftarrow x \+ \\epsilon s\_\\theta(x) \+ \\dots$ | $x' \\leftarrow x \+ \\epsilon (s\_\\theta(x) \+ \\lambda \\nabla \\log \\frac{D\_\\phi(x)}{1-D\_\\phi(x)}) \+ \\dots$ |
| **목적** | SDE 이산화 오차 보정 | SDE 오차 보정 \+ **분포 불일치(Density Mismatch) 능동적 수정** |

이 구조는 확산 모델이 대략적인 궤적을 잡으면(Predictor), 판별자가 정밀한 매니폴드 위치를 지적하여(Corrector) 밀어주는 형태로 작동합니다.

### **4.2 시간 의존적 판별자(Time-Dependent Discriminator) 도입**

1의 연구에 따르면 확산 모델은 $t=0$에서 $t=T$까지 다양한 잡음 레벨을 다룹니다. 일반적인 GAN 판별자는 잡음이 없는 깨끗한 데이터($t=0$)만 학습하므로, 잡음이 섞인 중간 단계 데이터 $x\_t$에 대해서는 유의미한 그래디언트를 제공할 수 없습니다. 이는 매니폴드 가설에 따라 $p\_{data}$와 $p\_{model}$의 서포트(support)가 겹치지 않기 때문입니다.1

따라서 실험적 성공을 위해서는 **시간 의존적 판별자(Time-Dependent Discriminator, TDD)** 도입이 필수적입니다.

* **구조:** NCSN++ 1나 DDPM의 U-Net 1과 유사하게, 판별자 $D\_\\phi(x, t)$도 시간 $t$를 입력으로 받아 해당 잡음 레벨에 맞는 결정 경계를 학습해야 합니다.  
* **학습 목표:** 각 시점 $t$에 대해, 확산 과정의 순방향 샘플 $x\_t \\sim q\_t(x)$를 'Real'로, 역방향 생성 과정의 샘플 $\\hat{x}\_t \\sim p\_t(x)$를 'Fake'로 구분합니다.  
* **Conditioning:** 시간 $t$는 Transformer의 정현파 위치 임베딩(Sinusoidal Positional Embedding) 1을 통해 주입되어야 판별자가 잡음의 강도를 인지하고 적절한 스케일의 그래디언트를 제공할 수 있습니다.

### **4.3 실험적 검증을 위한 구체적 설정 (Experimental Setup)**

제안된 알고리즘의 성능을 검증하고 기존 모델(Baseline)과 비교하기 위한 구체적인 실험 설정을 1의 기준에 맞춰 제안합니다.

#### **4.3.1 데이터셋 및 전처리**

* **CIFAR-10 (32x32):** 이미지 생성의 표준 벤치마크. $32 \\times 32$ 해상도는 빠른 실험 주기를 가능하게 합니다. 1에 따라 0-255 픽셀 값을 $\[-1, 1\]$로 정규화합니다.  
* **LSUN Bedroom/Church (256x256):** 고해상도 및 복잡한 텍스처 생성 능력 검증용. 1와 동일하게 전처리합니다.  
* **CelebA-HQ (256x256):** 인물 얼굴의 세밀한 특징과 매니폴드 보간(Interpolation) 성능 평가용.

#### **4.3.2 네트워크 아키텍처 구성**

* **스코어 네트워크 ($s\_\\theta$):** 1에서 제안한 **U-Net** 구조를 기반으로 합니다.  
  * Self-Attention 메커니즘을 $16 \\times 16$ 해상도에 적용하여 전역적 의존성을 포착.  
  * Group Normalization 사용.  
  * 1의 **NCSN++** (Deep) 구조를 채택하여 깊이를 2배로 늘리고 FIR(Finite Impulse Response) 업/다운샘플링을 적용하면 FID 성능을 극대화할 수 있습니다.  
* **판별자 네트워크 ($D\_\\phi$):** 스코어 네트워크와 유사한 U-Net 백본을 사용하되, 출력층을 스칼라 값(확률)으로 변경합니다.  
  * **Spectral Normalization**을 적용하여 Lipschitz 연속성을 보장해야 합니다. 이는 판별자의 그래디언트가 발산하지 않고 안정적인 교정 신호를 제공하기 위해 필수적입니다.1

#### **4.3.3 하이퍼파라미터 및 학습 전략**

* **확산 스케줄 ($\\beta\_t$):** 1에 따라 $T=1000$, $\\beta\_1=10^{-4}$에서 $\\beta\_T=0.02$로 선형적으로 증가하는 스케줄을 사용합니다.  
* **샘플링 파라미터:** PC 샘플러 사용 시, Corrector 단계의 스텝 사이즈 $\\epsilon$와 교정 강도 $\\lambda$에 대한 격자 탐색(Grid Search)이 필요합니다. 1에서는 SNR(Signal-to-Noise Ratio) 기반으로 스텝 사이즈를 자동 조절하는 방식을 제안하므로 이를 차용합니다.  
* **Tweedie's Formula Denoising:** 판별자에 잡음이 섞인 $x\_t$를 그대로 넣는 것보다, Tweedie 공식을 이용해 $x\_t$에서 예측된 $x\_0$ (denoised estimate)를 판별자에 입력하는 것이 판별자가 의미론적 특징을 파악하는 데 유리할 수 있습니다.

#### **4.3.4 평가지표**

* **FID (Fréchet Inception Distance):** 이미지 품질과 다양성을 종합적으로 평가하는 주 지표. 1의 3.17 (CIFAR-10) 이하를 목표로 합니다.  
* **IS (Inception Score):** 이미지의 명확성과 다양성 평가. 1의 9.89 이상을 목표로 합니다.  
* **NLL (Negative Log-Likelihood):** 분포의 커버리지 평가. 판별자 교정이 모드 붕괴를 유발하지 않고 전체 분포를 잘 커버하는지 확인하기 위해 필수적입니다.

---

## **5\. 심층 분석: 제안 모델의 잠재적 영향력과 인사이트**

### **5.1 에너지 기반 모델(EBM)과 GAN의 통합적 관점**

본 연구에서 제안하는 접근 방식은 GAN과 EBM(Energy-Based Models)의 경계를 허무는 시도입니다. GAN의 판별자는 두 분포 사이의 에너지 차이(Energy Difference)를 학습하는 것으로 볼 수 있고, 확산 모델은 에너지의 기울기(Gradient)를 학습하는 것입니다.

* **기존 한계:** 스코어 매칭은 국소적인 기울기 정보만 학습하므로, 데이터의 모드(Mode)들이 서로 멀리 떨어져 있을 때 모드 간의 상대적 가중치(Mixing weight)를 정확히 학습하지 못하는 'Mixing Problem'이 발생합니다.1  
* **해결:** 판별자는 전체 매니폴드를 조망하며 분포 간의 비율을 추정하므로, 이러한 전역적 불균형을 감지할 수 있습니다. 즉, 본 알고리즘은 \*\*국소적 정밀함(Score)\*\*과 \*\*전역적 균형(Discriminator Ratio)\*\*을 결합하여 생성 모델의 근본적인 딜레마를 해결하는 열쇠가 될 수 있습니다.

### **5.2 잠재 공간 보간(Interpolation)의 선형성 개선**

1에서 AAE가 보여주었듯, 판별자를 통한 잠재 공간 정규화는 데이터 매니폴드 상에서의 이동을 더욱 부드럽게 만듭니다. 확산 모델에서 제안된 교정 알고리즘을 적용할 경우, 두 샘플 사이를 보간(Interpolation)할 때 발생하는 궤적이 저밀도 영역(비현실적인 이미지 영역)을 우회하여 고밀도 영역(데이터 매니폴드)을 따라 이동하도록 강제할 수 있습니다. 이는 1에서 보여준 보간 결과보다 더욱 자연스럽고 아티팩트가 적은 결과를 기대하게 합니다.

### **5.3 적대적 학습의 안정화**

전통적인 GAN 학습은 생성자와 판별자의 균형이 깨지기 쉬워 학습이 매우 불안정합니다. 그러나 본 제안에서는 생성자 역할을 하는 확산 모델이 이미 MLE(Maximum Likelihood Estimation) 또는 스코어 매칭 기반으로 안정적으로 학습됩니다. 판별자는 단지 '보조적'인 교정 신호만을 제공하므로, GAN 특유의 모드 붕괴나 진동(Oscillation) 문제로부터 훨씬 자유롭습니다. 이는 GAN의 고품질 생성 능력과 확산 모델의 안정성을 동시에 취하는 전략입니다.

---

## **6\. 결론 및 향후 연구 제언**

본 보고서는 GAN 판별자를 밀도 비율 추정기로 재해석하여 스코어 기반 확산 모델의 랑주뱅 역학 샘플링을 교정하는 알고리즘의 수학적, 실험적 타당성을 검증하였습니다.

1. **수학적 검증:** 최적 판별자의 출력이 실제 데이터와 모델 분포의 비율과 직결됨을 보였고, 이를 로그 미분하여 스코어 함수의 오차를 보정하는 벡터장으로 변환할 수 있음을 증명하였습니다.  
2. **알고리즘 제안:** 1의 PC 샘플러 구조 내에 시간 의존적 판별자의 그래디언트를 주입하는 **DRE-LD (Density-Ratio Enhanced Langevin Diffusion)** 알고리즘을 구체화하였습니다.  
3. **실험적 보강:** NCSN++ 및 DDPM U-Net 아키텍처, 스펙트럴 정규화, 노이즈 스케줄링 등 최신 연구 결과 1를 반영한 구체적인 실험 셋업을 제시하였습니다.

이 접근법은 단순히 두 모델을 섞는 것을 넘어, 스코어 매칭의 국소적 한계와 GAN의 학습 불안정성을 상호 보완하는 이론적 통합을 이루어냅니다. 향후 연구에서는 이 알고리즘을 통해 샘플링 스텝 수($T$)를 획기적으로 줄이거나(가속화), 조건부 생성(Conditional Generation)에서 가이던스(Guidance)의 역할을 판별자가 대체하는 방향으로 확장할 것을 제안합니다. 이는 생성 AI 분야에서 고품질, 고다양성, 고속 샘플링의 세 마리 토끼를 잡는 중요한 전환점이 될 것입니다.

### **참고 문헌 요약 (In-text Citations)**

* 1 Goodfellow et al.: GAN의 원리, 판별자의 최적해 및 밀도 비율 추정의 근거.  
* 1 Kingma & Welling: VAE의 잠재 공간 및 사후 분포 개념.  
* 1 Makhzani et al.: AAE를 통한 잠재 공간 정규화 및 판별자의 역할.  
* 1 Song et al.: SDE 기반 확산 모델, PC 샘플러, VE/VP SDE 구분.  
* 1 Song & Ermon: 스코어 매칭의 원리, 매니폴드 가설, NCSN.  
* 1 Ho et al.: DDPM의 구체적 구현, $L\_{simple}$ 목적 함수, U-Net 구조.

#### **참고 자료**

1. 01.Generative Adversarial Nets(GAN).pdf