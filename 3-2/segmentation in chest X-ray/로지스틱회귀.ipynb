{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de95d99",
   "metadata": {},
   "source": [
    "다른 사람들은 우리 프로젝트와 관련이 있는 분류 예제를 가져올것이라 생각.\n",
    "나는 우리 문제와는 거리가 멀지만 알아두면 좋은 분류 문제를 가져옴."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10ec1a",
   "metadata": {},
   "source": [
    "### 공부 시간에 따른 시험 합격 예측 (로지스틱 회귀)\n",
    "\n",
    "이 예제는 **공부한 시간**이라는 독립 변수(X)를 사용하여, \\*\\*시험 합격 여부(0: 불합격, 1: 합격)\\*\\*라는 종속 변수(y)를 예측하는 이진 분류 모델을 만듭니다.  \n",
    "`scikit-learn` 라이브러리를 사용하여 로지스틱 회귀 모델을 간단하게 구현하고, `matplotlib`으로 결과를 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. 예제 데이터 생성\n",
    "# X: 공부 시간 (hours)\n",
    "X = np.array([[0.5], [1.0], [1.5], [2.0], [2.5], [3.0], [3.5], [4.0], [4.5], [5.0], [5.5], [6.0]])\n",
    "# y: 합격 여부 (0: Fail, 1: Pass)\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2705f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, np.shape(X), np.shape(y), type(X), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a25c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 로지스틱 회귀 모델 생성 및 학습\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ab81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 결과 시각화\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# 원본 데이터 점 찍기 (Scatter plot)\n",
    "plt.scatter(X, y, color='blue', zorder=20, label='Actual Data')\n",
    "\n",
    "# 로지스틱 회귀 곡선 그리기\n",
    "X_test = np.linspace(-1, 7, 300).reshape(-1, 1) # 예측을 위한 x값 범위\n",
    "y_prob = model.predict_proba(X_test)[:, 1] # 클래스 1(합격)에 대한 확률 예측\n",
    "plt.plot(X_test, y_prob, color='red', linewidth=3, label='Logistic Regression Curve')\n",
    "\n",
    "# 결정 경계선(확률=0.5) 표시\n",
    "decision_boundary = -model.intercept_ / model.coef_[0]\n",
    "plt.axvline(x=decision_boundary, color='green', linestyle='--', label='Decision Boundary')\n",
    "\n",
    "# 그래프 제목 및 라벨 설정\n",
    "plt.title('Study Hours vs. Pass/Fail') # 그래프 제목\n",
    "plt.xlabel('Hours Studied') # x축 이름\n",
    "plt.ylabel('Probability of Passing') # y축 이름\n",
    "plt.yticks([0.0, 0.5, 1.0])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, np.shape(X_test), type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b6f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob, np.shape(y_prob), type(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba563e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "-model.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 새로운 데이터 예측\n",
    "# 예를 들어 3.7시간과 3.8시간 공부했을 때의 합격 확률은?\n",
    "new_hours = np.array([[3.7], [3.8]])\n",
    "predicted_proba = model.predict_proba(new_hours)\n",
    "\n",
    "print(f\"결정 경계(Decision Boundary)는 약 {decision_boundary[0]:.2f} 시간입니다.\")\n",
    "print(f\"3.7시간 공부했을 때 합격 확률: {predicted_proba[0][1]:.2%}\")\n",
    "print(f\"3.8시간 공부했을 때 합격 확률: {predicted_proba[1][1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71c274",
   "metadata": {},
   "source": [
    "## From Scratch\n",
    "Numpy 라이브러리만을 사용하여 로지스틱 회귀의 핵심 알고리즘을 구현합니다.  \n",
    "모델은 **경사 하강법(Gradient Descent)**을 통해 데이터에 가장 잘 맞는 최적의 가중치(Weight)를 점진적으로 찾아 나갑니다.  \n",
    "이 과정은 마치 안개가 낀 산에서 가장 낮은 지점을 찾기 위해 계속해서 경사가 가파른 쪽으로 한 걸음씩 내려가는 것과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeba91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 시그모이드 함수 정의\n",
    "# 모든 입력값을 0과 1 사이의 확률 값으로 변환하는 함수\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# 2. 파라미터(가중치) 초기화 및 데이터 준비\n",
    "# X: 공부 시간 (hours)\n",
    "X_data = np.array([[0.5], [1.0], [1.5], [2.0], [2.5], [3.0], [3.5], [4.0], [4.5], [5.0], [5.5], [6.0]])\n",
    "# y: 합격 여부 (0: Fail, 1: Pass)\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]).reshape(-1, 1) # y를 열벡터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1870cb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.5],\n",
       "        [1. ],\n",
       "        [1.5],\n",
       "        [2. ],\n",
       "        [2.5],\n",
       "        [3. ],\n",
       "        [3.5],\n",
       "        [4. ],\n",
       "        [4.5],\n",
       "        [5. ],\n",
       "        [5.5],\n",
       "        [6. ]]),\n",
       " (12, 1),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data, np.shape(X_data), type(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2dd80a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]]),\n",
       " (12, 1),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, np.shape(y), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97af2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터(X)에 편향(bias)을 위한 1의 열을 추가합니다.\n",
    "# 이는 y = wx + b 형태의 수식에서 y절편 b를 학습하기 위함입니다.\n",
    "X = np.c_[np.ones((len(X_data), 1)), X_data] # np.ones((12, 1))은 12행 1열의 1로 채워진 행렬을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16491a0",
   "metadata": {},
   "source": [
    "왜 편향을 추가하는 이유\n",
    "편향(bias) 항을 추가하는 이유는 모델이 데이터의 중심을 더 잘 맞출 수 있도록 하기 위함입니다.  \n",
    "편향 항이 없으면 모델은 원점을 지나야 하므로 데이터의 분포를 제대로 반영하지 못할 수 있습니다.\n",
    "\n",
    "ex. y = wx + b (b는 편향 항)\n",
    "이때 b가 없다면 모델은 y = wx 형태가 되어 원점을 지나야 합니다.  \n",
    "편향 항 b가 있으면 모델이 데이터의 중심을 더 잘 맞출 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee490e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cb27aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0.5],\n",
       "       [1. , 1. ],\n",
       "       [1. , 1.5],\n",
       "       [1. , 2. ],\n",
       "       [1. , 2.5],\n",
       "       [1. , 3. ],\n",
       "       [1. , 3.5],\n",
       "       [1. , 4. ],\n",
       "       [1. , 4.5],\n",
       "       [1. , 5. ],\n",
       "       [1. , 5.5],\n",
       "       [1. , 6. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[np.ones((12, 1)), X_data] # X_data 첫번쨰 열에 편향(bias, 1) 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb625e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1. , 0.5],\n",
       "        [1. , 1. ],\n",
       "        [1. , 1.5],\n",
       "        [1. , 2. ],\n",
       "        [1. , 2.5],\n",
       "        [1. , 3. ],\n",
       "        [1. , 3.5],\n",
       "        [1. , 4. ],\n",
       "        [1. , 4.5],\n",
       "        [1. , 5. ],\n",
       "        [1. , 5.5],\n",
       "        [1. , 6. ]]),\n",
       " (12, 2),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, np.shape(X), type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b11d7de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.],\n",
       "        [0.]]),\n",
       " (2, 1),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치(weights)를 0으로 초기화합니다. [b, w] 형태가 됩니다.\n",
    "weights = np.zeros((X.shape[1], 1)) # np.zeros((2, 1))과 동일\n",
    "weights, np.shape(weights), type(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62985d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 z 값:[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape: (12, 1)\n",
      "첫번째 h 값:[[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]], shape: (12, 1)\n"
     ]
    }
   ],
   "source": [
    "z = np.dot(X, weights) # X와 weights의 행렬 곱\n",
    "print(f\"첫번째 z 값:{z}, shape: {np.shape(z)}\")\n",
    "h = sigmoid(z) # 시그모이드 함수 적용\n",
    "print(f\"첫번째 h 값:{h}, shape: {np.shape(h)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894e0c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 error 값:[[ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]\n",
      " [-0.5]], shape: (12, 1)\n"
     ]
    }
   ],
   "source": [
    "error = h - y # 예측값(h)과 실제값(y)의 차이\n",
    "print(f\"첫번째 error 값:{error}, shape: {np.shape(error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee5fbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(y) # 데이터 개수\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b46c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ],\n",
       "       [-0.75]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = np.dot(X.T, error) / m\n",
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed5cee45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ],\n",
       "        [0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ]]),\n",
       " (2, 12),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T, np.shape(X.T), type(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "weights -= learning_rate * gradient\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33da7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d20fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 하이퍼파라미터 설정\n",
    "learning_rate = 0.1  # 학습률: 한 걸음에 얼마나 이동할지 결정\n",
    "iterations = 100000 # 학습 반복 횟수\n",
    "\n",
    "# 4. 경사 하강법(Gradient Descent)을 이용한 모델 학습\n",
    "m = len(y) # 데이터 개수\n",
    "\n",
    "for i in range(iterations):\n",
    "    # 예측값 계산 (가설 함수)\n",
    "    z = np.dot(X, weights)\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    # 오차(error) 계산\n",
    "    error = h - y\n",
    "    \n",
    "    # 경사(gradient) 계산: 비용 함수를 가중치로 미분한 결과\n",
    "    gradient = np.dot(X.T, error) / m\n",
    "    \n",
    "    # 가중치 업데이트\n",
    "    weights -= learning_rate * gradient\n",
    "    \n",
    "    # 일정 주기마다 비용(Cost) 출력 (학습이 잘 되는지 확인용)\n",
    "    if i % 10000 == 0:\n",
    "        # 비용 함수(로그 손실) 계산\n",
    "        cost = -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "        print(f\"Iteration {i}: Cost = {cost:.4f}\")\n",
    "\n",
    "print(\"\\n** 학습 완료! **\")\n",
    "print(f\"최종 가중치(weights): \\n b (bias) = {weights[0][0]:.4f} \\n w (slope) = {weights[1][0]:.4f}\")\n",
    "\n",
    "\n",
    "# 5. 결과 시각화\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_data, y, color='blue', zorder=20, label='Actual Data')\n",
    "\n",
    "# 학습된 S자 곡선 그리기\n",
    "X_test = np.linspace(-1, 7, 300)\n",
    "X_test_with_bias = np.c_[np.ones((len(X_test), 1)), X_test]\n",
    "y_prob = sigmoid(np.dot(X_test_with_bias, weights))\n",
    "plt.plot(X_test, y_prob, color='red', linewidth=3, label='Learned Curve')\n",
    "\n",
    "# 결정 경계선 계산 및 표시 (z = w*x + b = 0 이 되는 지점)\n",
    "decision_boundary = -weights[0][0] / weights[1][0]\n",
    "plt.axvline(x=decision_boundary, color='green', linestyle='--', label='Decision Boundary')\n",
    "\n",
    "# 그래프 제목 및 라벨 설정\n",
    "plt.title('Study Hours vs. Pass/Fail (Manual Implementation)') # 그래프 제목\n",
    "plt.xlabel('Hours Studied') # x축 이름\n",
    "plt.ylabel('Probability of Passing') # y축 이름\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"계산된 결정 경계는 약 {decision_boundary:.2f} 시간입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273510a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
