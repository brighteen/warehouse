1. 자연어 처리의 분석 과정에 대해 서술하시오.  
형태소 분석, 구문 분석, 의미 분석, 담화 분석의 순서로 이루어지며, 각 단계에서 텍스트의 구조와 의미, 맥락를 점진적으로 파악한다.

2. 한국어 자연어 처리가 훨씬 어려운 이유에 대해 설명하시오.
```
1. 한국어는 교착어이다.
어간에 접사가 붙는 교착어가 있어 형태소 분석이 어렵다.
2. 한국어는 띄어쓰기가 잘 지켜지지 않음.
3. 한국어는 어순이 바뀌어도 의미가 통함.
4. 한자어라는 특성상 하나의 음절조차도 다른 의미를 가지는 중의성을 가짐.
5. 주어가 손쉽게 생략된다.
6. 데이터가 영어에 비해 많이 부족하다.
영어에 비해 한국어 데이터와 오픈 소스 라이브러리 등이 부족.
7. 언어 특화된 오픈 소스가 부족하다.
```

3. 대표적인 통계기반 자연어 처리 라이브러리의 예를 들고 설명하시오.
규칙의 사전 정의를 통계적으로 처리함.
컴퓨터 성능이 발전하여 대량의 데이터를 빠르게 처리할 수 있게되면서 발전했지만 여전히 선형적인 분석이기에 복잡한 규칙을 처리하기에 어려움.

4. 대표적인 기계학습/딥러닝 기반 라이브러리의 예를 들고 설명하시오.
대량의 데이터를 기반으로 학습을 통한 모델링으로 자연어를 처리함. 이때 비선형적인 데이터를 예측할 수 있음.

5. 대표적인 한글 자연어 처리 라이브러리의 예를 들고 설명하시오.
Okt: 텍스트에서 형태소, 명사, 어절, 품사 정보를 추출하는 기능을 제공하는 한국어 형태소 분석기.

6. 자연어 데이터 전처리의 과정에 대해 설명하시오. ★
```
1 자연어 데이터 수집 및 전처리(구두점, 특수 기호 및 문자 제거)
2 토큰화: 주어진 코퍼스에서 토큰으로 분리하는데 이때 문장 토큰화와 단어 토큰화로 나뉨. 이때 띄어쓰기, 철자 및 맞춤법을 고려해야함.
3 정제 (Cleaning) 불용어 제거
4 정규화 (Normalization): 대소문자 통합, 표제어 추출, 어간추출
5 불용어 제거
6 품사 태깅
7 인코딩 및 벡터화를 통해 텍스트를 숫자로 매핑.
8 패딩/잘라내기: 시퀀스 길이를 맞추기 위해 패딩 또는 잘라내기를 수행.
```

7. LSTM의 작동원리에 대해 설명하시오. ★
LSTM(Long Short-Term Memory)은 RNN의 일종으로, 장기 의존성 문제를 해결하기 위해 고안된 신경망 구조임. LSTM은 셀 상태(cell state)와 게이트(gate) 메커니즘을 사용하여 정보를 선택적으로 기억하거나 잊어버릴 수 있음. 주요 구성 요소로는 입력 게이트, 삭제 게이트, 출력 게이트가 있으며, 이를 통해 중요한 정보를 장기간 유지하고 불필요한 정보를 제거함으로써 시퀀스 데이터의 패턴을 효과적으로 학습함.