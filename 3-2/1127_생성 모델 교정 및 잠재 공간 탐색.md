

# **GAN 판별자를 활용한 밀도 비율 추정 기반 Score-based/Diffusion 모델의 잠재 공간 탐색 교정: 수학적 타당성 검증 및 실험적 보강 방안**

## **요약**

본 연구 보고서는 현대 생성 모델링의 두 가지 주류인 Score-based Generative Models (SGM)과 Generative Adversarial Networks (GAN)의 장점을 융합하여, 확산 모델(Diffusion Model)의 샘플링 과정에서 발생하는 잠재적 불안정성을 해결하는 새로운 하이브리드 프레임워크를 제안한다. Score-based 모델은 확률 미분 방정식(SDE)을 통해 데이터 분포를 점진적으로 노이즈로 변환하고 이를 역으로 복원하는 과정을 학습함으로써 고품질의 이미지 생성을 가능하게 하였다. 그러나 데이터 밀도가 낮은 영역(Low-density regions)에서의 스코어 추정 부정확성은 샘플링 궤적의 이탈을 초래하고 생성 속도와 품질의 저하를 야기한다. 본 연구는 GAN의 판별자(Discriminator)가 제공하는 밀도 비율(Density Ratio) 정보를 활용하여 이러한 스코어 오차를 실시간으로 교정(Correction)하는 수학적 메커니즘을 규명한다. 구체적으로, 판별자의 그래디언트가 역 확산 과정의 드리프트 항을 수정하는 벡터장(Vector Field)으로 작용함을 증명하고, 이를 Predictor-Corrector 샘플러에 통합하는 알고리즘을 제시한다. 또한 CIFAR-10 및 고해상도 데이터셋에 대한 광범위한 실험 설계를 통해 제안된 방법론이 FID, Inception Score, Negative Log-Likelihood (NLL) 등 정량적 지표에서 기존 SOTA 모델을 능가할 수 있는 잠재력을 가짐을 논증한다.

## **1\. 서론: 생성 모델링의 패러다임 전환과 수렴**

인공지능 기반의 생성 모델링(Generative Modeling)은 관측된 데이터 $x$의 기저에 존재하는 확률 분포 $p\_{data}(x)$를 근사하고, 이 분포로부터 새로운 샘플을 효율적으로 추출하는 것을 궁극적인 목표로 한다. 지난 10년 간 이 분야는 크게 우도 기반(Likelihood-based) 모델과 암시적(Implicit) 생성 모델이라는 두 가지 큰 줄기로 발전해 왔다. 변분 오토인코더(Variational Autoencoders, VAE) 1와 같은 우도 기반 모델은 데이터의 로그 우도에 대한 하한(ELBO)을 최대화하는 방식으로 학습의 안정성을 확보하고 잠재 공간의 유의미한 표현 학습(Representation Learning)을 가능하게 했다. 그러나 VAE는 근사 사후 분포(Approximate Posterior)의 가정과 재구성 손실(Reconstruction Loss)의 특성으로 인해 생성된 이미지가 다소 흐릿(Blurry)해지는 경향이 있었다. 반면, Goodfellow et al.이 제안한 적대적 생성 신경망(GAN) 1은 생성자(Generator)와 판별자(Discriminator) 간의 미니맥스 게임(Minimax Game)을 통해 명시적인 밀도 함수 정의 없이도 매우 선명하고 사실적인 이미지를 생성하는 데 성공했다. 하지만 GAN은 학습 과정이 매우 불안정하고, 데이터 분포의 일부만을 학습하는 모드 붕괴(Mode Collapse) 문제에서 자유롭지 못했다.

최근 등장한 Score-based Generative Models (SGM)과 Denoising Diffusion Probabilistic Models (DDPM)은 이러한 이분법적 구도를 깨고 새로운 패러다임을 제시하였다. Song & Ermon 1은 데이터 분포의 스코어(Score, $\\nabla\_x \\log p(x)$)를 직접 추정하고 랑주뱅 동역학(Langevin Dynamics)을 통해 샘플링하는 방식을 제안하였으며, Ho et al. 1은 이를 확률적 확산 과정의 역과정으로 공식화하여 학습 안정성과 샘플 다양성을 동시에 확보하였다. 특히 Song et al. 1은 이 두 가지 접근법을 확률 미분 방정식(Stochastic Differential Equations, SDE)이라는 통합된 프레임워크로 재해석함으로써, 연속적인 시간 $t$ 위에서의 확산과 역확산 과정을 수학적으로 엄밀하게 정의하였다. 이 프레임워크는 이산적인 시간 단계에 의존하던 기존 모델들의 한계를 극복하고, 다양한 수치 해석적 SDE 솔버를 적용할 수 있는 유연성을 제공하였다.

그럼에도 불구하고 현재의 Score-based 모델들은 여전히 해결해야 할 난제를 안고 있다. 가장 핵심적인 문제는 데이터가 희소하게 존재하는 저밀도 영역(Low-density regions)에서의 스코어 추정 정확도이다.1 학습 데이터는 고차원 공간 내의 저차원 매니폴드(Manifold)에 집중되어 있기 때문에, 매니폴드에서 멀리 떨어진 영역에서는 스코어 네트워크가 학습 신호를 충분히 받지 못한다. 결과적으로 샘플링 과정에서 궤적이 이 저밀도 영역을 통과할 때 잘못된 방향으로 유도될 위험이 있으며, 이는 생성된 결과물의 품질 저하나 아티팩트(Artifact) 발생으로 이어진다.

본 보고서는 이러한 문제를 해결하기 위해 GAN의 판별자 메커니즘을 SDE 기반의 확산 모델에 도입하는 하이브리드 접근법을 제안한다. GAN의 판별자는 본질적으로 실제 데이터 분포와 생성 모델 분포 간의 비율(Density Ratio)을 추정하는 역할을 수행한다.1 우리는 이 밀도 비율 정보가 스코어 네트워크의 추정 오차를 보정하는 강력한 신호로 활용될 수 있음을 주목한다. Adversarial Autoencoder (AAE) 1가 잠재 공간의 분포를 사전 분포에 일치시키기 위해 판별자를 활용했던 것처럼, 우리는 역 확산 과정의 각 시점에서 판별자의 그래디언트를 활용하여 샘플링 궤적을 데이터 매니폴드로 강하게 유인하는 '교정(Correction)' 메커니즘을 설계한다. 이는 SDE의 수학적 유연성과 GAN의 분포 매칭 능력을 결합하여 생성 모델링의 성능을 한 단계 도약시키려는 시도이다.

## **2\. 이론적 배경 및 선행 연구 분석**

본 장에서는 제안하는 방법론의 기초가 되는 Score-based 모델링, 확산 확률 모델, 그리고 GAN의 이론적 배경을 심층적으로 분석한다.

### **2.1 스코어 매칭과 랑주뱅 동역학의 심화 분석**

Score-based 모델의 핵심 아이디어는 확률 밀도 함수 자체를 모델링하는 대신, 그 로그 밀도의 그래디언트인 스코어 함수 $\\nabla\_x \\log p(x)$를 모델링하는 것이다. 이는 정규화 상수(Normalization Constant)를 계산할 필요가 없다는 점에서 매우 효율적이다. Song과 Ermon은 신경망 $s\_\\theta(x)$를 이용하여 데이터 분포의 스코어를 근사하는 스코어 매칭(Score Matching) 기법을 활용했다.1

$$ \\mathcal{L}(\\theta) \= \\frac{1}{2} \\mathbb{E}*{p*{data}} \[ | s\_\\theta(x) \- \\nabla\_x \\log p\_{data}(x) |\_2^2 \] $$

그러나 실제 데이터 분포 $p\_{data}(x)$의 스코어를 알 수 없으므로, 부분 적분(Integration by Parts)을 이용한 Fisher Divergence의 변형이나 Denoising Score Matching 기법이 사용된다. 특히 Denoising Score Matching은 데이터에 가우시안 노이즈를 주입한 분포 $q\_\\sigma(\\tilde{x}|x)$의 스코어를 학습하는 방식으로, 계산 효율성이 높고 안정적이다.

$$ \\mathcal{L}*{DSM}(\\theta) \= \\frac{1}{2} \\mathbb{E}*{p\_{data}(x)} \\mathbb{E}*{\\tilde{x} \\sim \\mathcal{N}(x, \\sigma^2 I)} \[ | s*\\theta(\\tilde{x}) \- \\nabla\_{\\tilde{x}} \\log q\_\\sigma(\\tilde{x}|x) |\_2^2 \] $$

여기서 중요한 문제는 '매니폴드 가설(Manifold Hypothesis)'에 기인한다. 1의 분석에 따르면, 실제 고차원 데이터는 전체 공간이 아닌 매우 낮은 차원의 매니폴드에 국한되어 분포한다. 이 경우 매니폴드 밖의 영역에서는 스코어가 정의되지 않거나, 정의되더라도 학습 데이터가 없어 추정이 불가능하다. Song & Ermon은 이를 해결하기 위해 데이터에 다양한 크기의 노이즈 $\\{\\sigma\_i\\}\_{i=1}^N$를 주입하여 분포의 서포트(Support)를 전체 공간으로 확장하는 Noise Conditional Score Network (NCSN) 방식을 제안했다. 큰 노이즈 $\\sigma\_1$은 데이터 분포의 모드(Mode)들을 연결하여 전역적인 구조를 학습하게 하고, 작은 노이즈 $\\sigma\_N$은 미세한 디테일을 학습하게 한다.

샘플링 단계에서는 랑주뱅 동역학(Langevin Dynamics)을 사용한다. 이는 임의의 초기 상태에서 시작하여 스코어 함수가 가리키는 방향(밀도가 증가하는 방향)으로 이동하고, 적절한 노이즈를 주입하여 국소 최적점(Local Optima)에 갇히는 것을 방지한다.

$$ x\_{t} \= x\_{t-1} \+ \\frac{\\epsilon}{2} \\nabla\_x \\log p(x\_{t-1}) \+ \\sqrt{\\epsilon} z\_t, \\quad z\_t \\sim \\mathcal{N}(0, I) $$

NCSN은 이 과정을 어닐링된 랑주뱅 동역학(Annealed Langevin Dynamics)으로 확장하여, 큰 노이즈 레벨에서 시작하여 점진적으로 노이즈를 줄여나가는 방식을 취한다. 이는 시뮬레이티드 어닐링(Simulated Annealing)과 유사하게, 초기에는 상태 공간을 넓게 탐색하고 후기에는 세밀한 구조를 확정 짓는 전략이다.1

### **2.2 Denoising Diffusion Probabilistic Models (DDPM)**

Ho et al. 1이 제안한 DDPM은 비평형 열역학에서 영감을 받아 데이터에 노이즈를 서서히 주입하여 정보를 파괴하는 확산 과정(Forward Process)과 이를 복원하는 역 과정(Reverse Process)을 마르코프 체인으로 모델링한다. 확산 과정은 고정된 분산 스케줄 $\\beta\_t$에 따라 다음과 같이 정의된다.

$$q(x\_t | x\_{t-1}) \= \\mathcal{N}(x\_t; \\sqrt{1-\\beta\_t} x\_{t-1}, \\beta\_t I)$$  
역 과정은 학습 가능한 파라미터 $\\theta$를 가진 가우시안 분포로 모델링된다.

$$p\_\\theta(x\_{t-1} | x\_t) \= \\mathcal{N}(x\_{t-1}; \\mu\_\\theta(x\_t, t), \\Sigma\_\\theta(x\_t, t))$$  
DDPM의 중요한 기여는 변분 하한(ELBO)의 최적화가 결국 매 시점에서의 노이즈 예측 문제(Denoising)로 귀결됨을 보인 것이다. 구체적으로, $\\mu\_\\theta$를 직접 예측하는 대신 $x\_t$에 포함된 노이즈 $\\epsilon$을 예측하도록 네트워크를 재매개변수화(Reparameterization)함으로써 학습 효율을 높였다. Ho et al.은 이 목적 함수가 가중치가 조절된 스코어 매칭과 수학적으로 동치임을 밝혀, DDPM과 NCSN이 본질적으로 동일한 목표를 지향함을 입증했다.1 DDPM은 NCSN과 달리 단일 네트워크를 사용하여 모든 타임스텝의 노이즈를 예측하며, 고품질의 이미지 샘플링에 성공하여 GAN에 필적하는 성능을 보여주었다.

### **2.3 확률 미분 방정식(SDE)을 통한 통합 프레임워크**

Song et al. 1은 이산적인 타임스텝을 가진 NCSN과 DDPM을 연속 시간 $t \\in$로 일반화하여 확률 미분 방정식(SDE) 프레임워크를 제안하였다. 데이터 분포 $p\_0$를 사전 분포 $p\_T$로 변환하는 순방향 SDE는 다음과 같다.

$$dx \= f(x, t)dt \+ g(t)dw$$  
여기서 $f(x, t)$는 드리프트 계수(Drift Coefficient), $g(t)$는 확산 계수(Diffusion Coefficient), $w$는 브라운 운동(Brownian Motion)을 나타낸다. Anderson의 정리에 따르면, 이 확산 과정의 역과정 또한 SDE로 표현될 수 있다.

$$dx \= \[f(x, t) \- g(t)^2 \\nabla\_x \\log p\_t(x)\]dt \+ g(t) d\\bar{w}$$  
이 역방향 SDE(Reverse-time SDE)는 오직 각 시점에서의 주변 확률 분포의 스코어 $\\nabla\_x \\log p\_t(x)$에만 의존한다. 따라서 신경망을 통해 시간 의존적 스코어 함수 $s\_\\theta(x, t)$를 학습하면, 수치적 SDE 솔버(Euler-Maruyama 등)를 사용하여 역 과정을 시뮬레이션함으로써 데이터 $x\_0$를 생성할 수 있다.

이 프레임워크는 NCSN과 DDPM을 각각 특정 SDE의 이산화(Discretization) 형태로 포괄한다. NCSN의 노이즈 교란 과정은 상태의 분산이 시간 흐름에 따라 발산하는 **Variance Exploding (VE) SDE**로, DDPM의 확산 과정은 상태의 분산이 일정하게 유지되는 **Variance Preserving (VP) SDE**로 해석된다.1 더 나아가 Song et al.은 **Probability Flow ODE**라는 결정론적 과정을 유도하여, SDE와 동일한 주변 분포를 가지면서도 노이즈 항이 없는 미분 방정식을 제시하였다. 이를 통해 정확한 우도(Likelihood) 계산과 잠재 공간에서의 부드러운 보간(Interpolation)이 가능해졌다.

| 모델 구분 | 이산형 모델 | 연속형 SDE 대응 | 특징 |
| :---- | :---- | :---- | :---- |
| **NCSN** | Annealed Langevin Dynamics | **VE SDE** ($dx \= \\sqrt{\\frac{d\[\\sigma^2(t)\]}{dt}} dw$) | 분산이 발산함 ($\\sigma(t) \\to \\infty$). 전역적 구조 학습에 유리. |
| **DDPM** | Ancestral Sampling | **VP SDE** ($dx \= \-\\frac{1}{2}\\beta(t)x dt \+ \\sqrt{\\beta(t)} dw$) | 분산이 1로 고정됨. 우도 계산 및 최적화에 유리. |
| **New** | \- | **sub-VP SDE** | VP SDE보다 분산이 작게 유지됨. 우도 성능이 우수함.1 |

### **2.4 기존 모델의 한계점: 저밀도 영역과 궤적 이탈**

SDE 프레임워크는 강력하지만, 여전히 '저밀도 영역(Low-density regions)' 문제를 안고 있다. 스코어 매칭 목적 함수는 데이터가 존재하는 영역($p\_{data}(x) \> 0$)에서 스코어 추정 오차를 최소화하도록 설계되어 있다. 따라서 데이터가 거의 존재하지 않는 저밀도 영역에서는 스코어 네트워크 $s\_\\theta(x, t)$의 출력이 부정확할 가능성이 높다.1 샘플링 과정에서 역방향 SDE의 궤적이 이 저밀도 영역을 통과하게 되면, 부정확한 드리프트 정보로 인해 궤적이 실제 데이터 매니폴드에서 멀어지게 된다. 이는 생성된 이미지에 부자연스러운 노이즈나 왜곡을 발생시키는 주된 원인이 된다. 특히 고차원 데이터일수록 대부분의 공간이 저밀도 영역이므로 이 문제는 더욱 심각해진다.

## **3\. GAN 판별자를 활용한 밀도 비율 추정의 수학적 타당성 검증**

본 장에서는 GAN의 판별자가 제공하는 정보가 어떻게 Score-based 모델의 샘플링 오차를 보정할 수 있는지 수학적으로 증명한다.

### **3.1 최적 판별자와 밀도 비율(Density Ratio)**

Goodfellow et al. 1의 연구에 따르면, GAN은 생성자 $G$와 판별자 $D$ 사이의 경쟁을 통해 학습된다. 판별자 $D(x)$는 입력 $x$가 실제 데이터 분포 $p\_{data}(x)$에서 왔을 확률을 출력한다. 고정된 생성자 $G$에 대해, 최적의 판별자 $D^\*(x)$는 다음 형태를 가진다.

$$D^\*(x) \= \\frac{p\_{data}(x)}{p\_{data}(x) \+ p\_{model}(x)}$$  
여기서 $p\_{model}(x)$는 생성자가 암시적으로 정의하는 분포이다. 이 식을 대수적으로 변형하면, 두 분포 간의 밀도 비율 $r(x)$를 판별자의 출력으로 표현할 수 있다.

$$r(x) \= \\frac{p\_{data}(x)}{p\_{model}(x)} \= \\frac{D^\*(x)}{1 \- D^\*(x)}$$  
판별자의 마지막 레이어 출력을 시그모이드 함수를 통과하기 전의 로짓(logit) 값 $O(x)$라고 하면 ($D(x) \= \\sigma(O(x))$), 위 식은 더욱 간단해진다.

$$O^\*(x) \= \\log \\frac{p\_{data}(x)}{p\_{model}(x)} \= \\log p\_{data}(x) \- \\log p\_{model}(x)$$  
즉, 잘 학습된 판별자의 로짓 값은 실제 데이터 분포와 모델 분포 간의 로그 밀도 차이를 나타낸다. 이는 판별자가 단순히 진짜/가짜를 구별하는 것을 넘어, 현재 모델 분포가 데이터 분포와 얼마나 다른지를 정량적으로 나타내는 지표로 활용될 수 있음을 시사한다.

### **3.2 스코어 보정(Score Correction)을 위한 그래디언트 유도**

Score-based 모델링의 목표는 $\\nabla\_x \\log p\_{data}(x)$를 추정하는 것이다. 그러나 우리가 학습한 스코어 네트워크 $s\_\\theta(x)$는 실제로는 현재 모델 분포의 스코어 $\\nabla\_x \\log p\_{model}(x)$를 근사하고 있다고 볼 수 있다 (특히 Denoising Score Matching이 모델 분포의 스코어를 학습하는 것과 동치임을 고려할 때). 따라서 실제 데이터 스코어와 학습된 스코어 사이에는 다음과 같은 오차가 존재한다.

$$ \\nabla\_x \\log p\_{data}(x) \= \\nabla\_x \\log p\_{model}(x) \+ \\nabla\_x \\log \\frac{p\_{data}(x)}{p\_{model}(x)} $$

앞서 유도한 밀도 비율 식을 대입하면 다음과 같은 중요한 관계식을 얻는다.

$$\\nabla\_x \\log p\_{data}(x) \\approx s\_\\theta(x) \+ \\nabla\_x O^\*(x)$$  
이 식은 \*\*판별자 로짓의 그래디언트 $\\nabla\_x O^\*(x)$가 스코어 추정의 편향(Bias)을 보정하는 수정항(Correction Term)\*\*으로 작용할 수 있음을 수학적으로 증명한다. $s\_\\theta(x)$가 불완전하여 샘플링 궤적이 $p\_{model}$ 쪽으로(즉, 데이터 매니폴드를 벗어나는 쪽으로) 흐를 때, 판별자의 그래디언트는 이를 $p\_{data}$ 쪽으로(데이터 매니폴드 쪽으로) 다시 끌어당기는 벡터장 역할을 수행한다.

### **3.3 Adversarial Autoencoders (AAE)와의 연결성 분석**

이러한 접근 방식은 Adversarial Autoencoders (AAE) 1의 원리와 깊은 연관이 있다. AAE는 오토인코더의 잠재 코드(Latent Code) 분포인 '집계된 사후 분포(Aggregated Posterior)' $q(z)$를 임의의 사전 분포 $p(z)$에 일치시키기 위해 GAN을 사용한다. AAE에서 판별자는 잠재 공간 상의 샘플이 실제 사전 분포에서 왔는지, 아니면 인코더가 생성한 분포에서 왔는지를 구별한다.

이를 확산 모델의 관점에서 재해석하면, 역 확산 과정의 각 시점 $t$에서의 잠재 변수 $x\_t$가 우리가 가정한 역방향 SDE의 주변 분포 $p\_t(x)$를 따르도록 강제하는 정규화(Regularization) 과정으로 볼 수 있다. AAE가 $q(z)$를 $p(z)$에 매칭시켜 생성 모델의 성능을 높이고 잠재 공간의 붕괴를 막았듯이, 본 연구에서 제안하는 판별자 기반 교정은 시간 $t$에 따른 샘플 분포 $p\_{\\theta, t}(x)$를 실제 확산 과정의 분포 $p\_t(x)$에 매칭시킴으로써 궤적 이탈을 방지한다. 특히 AAE가 잠재 공간에서의 불일치를 감지하여 인코더를 업데이트하는 방식은, 우리가 판별자 그래디언트를 통해 SDE의 드리프트를 수정하는 방식과 개념적으로 동형(Isomorphic)이다.

### **3.4 시간 의존적 판별자(Time-dependent Discriminator)의 필요성**

SDE 프레임워크에서는 데이터 분포가 시간에 따라 연속적으로 변화하여 $p\_t(x)$가 된다. $t=0$에서는 복잡한 데이터 분포이지만, $t=T$에서는 단순한 가우시안 분포가 된다. 따라서 단일 판별자로는 모든 시점의 분포 차이를 학습할 수 없다. 우리는 1에서 스코어 네트워크가 시간 $t$를 입력으로 받는 것처럼, 판별자 역시 시간 $t$에 조건부(Conditional)로 동작하는 \*\*시간 의존적 판별자 $D(x, t)$\*\*를 도입해야 함을 논증한다.

$$\\nabla\_x \\log p\_t(x) \\approx s\_\\theta(x, t) \+ \\lambda\_t \\nabla\_x O(x, t)$$  
여기서 $\\lambda\_t$는 시점에 따른 보정 강도를 조절하는 가중치 함수이다. $t$가 클수록(노이즈가 많을수록) 분포가 단순하여 스코어 추정이 정확하므로 $\\lambda\_t$를 작게 하고, $t$가 작을수록(데이터에 가까울수록) 매니폴드가 복잡해져 스코어 오차가 커지므로 $\\lambda\_t$를 크게 설정하는 것이 타당하다.

## **4\. 잠재 공간 탐색 교정 전략: Discriminator-Guided SDE Solver**

본 장에서는 앞서 유도한 수학적 원리를 바탕으로, 실제 SDE 샘플링 과정에 판별자를 통합하는 구체적인 알고리즘을 제안한다. Song et al. 1은 수치적 SDE 솔버(Predictor)와 MCMC 스텝(Corrector)을 결합한 **Predictor-Corrector (PC) 샘플러**를 제안하여 SOTA 성능을 달성했다. 우리는 이 프레임워크를 확장하여 **Discriminator-Guided Corrector**를 설계한다.

### **4.1 확장된 역방향 SDE 공식**

기존의 역방향 SDE 식에 판별자 보정항을 추가하면 다음과 같이 수정된 SDE를 얻을 수 있다.

$$dx \= \[f(x, t) \- g(t)^2 (s\_\\theta(x, t) \+ \\lambda \\nabla\_x O(x, t))\]dt \+ g(t) d\\bar{w}$$  
이 식은 기존 SDE의 드리프트 항에 판별자의 그래디언트가 추가된 형태이다. 물리적으로 해석하면, 기존의 드리프트가 "현재 위치에서 확률 밀도가 높아지는 방향"으로 입자를 이동시킨다면, 추가된 항은 "현재 위치가 실제 데이터 분포와 얼마나 다른지를 보정하는 방향"으로 힘을 가하는 것과 같다.

### **4.2 Discriminator-Guided PC Sampler 알고리즘**

우리는 1의 PC 샘플러 구조를 유지하되, Corrector 단계에서 판별자 정보를 주입하는 방식을 제안한다.

1. Predictor (예: Reverse Diffusion Solver): 현재 시점 $t\_{i+1}$의 샘플 $x\_{i+1}$로부터 다음 시점 $t\_i$의 샘플 $x\_i$를 예측한다. 이 단계는 기존의 스코어 함수 $s\_\\theta$만을 사용하여 SDE를 이산화(Discretization)한다.  
   $$ x\_i' \\leftarrow x\_{i+1} \- f\_{i+1}(x\_{i+1}) \+ G\_{i+1} G\_{i+1}^T s\_\\theta(x\_{i+1}, t\_{i+1}) \+ G\_{i+1} z\_{i+1} $$  
2. Discriminator-Guided Corrector (예: Modified Langevin Dynamics): 예측된 $x\_i'$가 데이터 매니폴드 위에 정확히 위치하도록 MCMC 단계를 수행한다. 이때 판별자의 그래디언트를 추가하여 수렴을 가속화하고 정확도를 높인다.  
   $$ x\_i \\leftarrow x\_i' \+ \\epsilon\_i (s\_\\theta(x\_i', t\_i) \+ \\gamma \\nabla\_x O(x\_i', t\_i)) \+ \\sqrt{2\\epsilon\_i} z\_i $$

여기서 $\\gamma$는 판별자 가이드의 세기를 조절하는 하이퍼파라미터이다. 이 방식은 기존의 Langevin Dynamics가 오직 스코어 정보에만 의존하여 저밀도 영역에서 헤매는 문제를 해결한다. 판별자는 저밀도 영역(즉, $p\_{model}$에서는 나올 수 있지만 $p\_{data}$에서는 나오기 힘든 영역)에 위치한 샘플에 대해 강한 페널티 신호를 주어, 샘플을 빠르게 고밀도 영역으로 밀어 넣는다.

### **4.3 잠재 공간에서의 교정 (Latent Space Correction)**

대부분의 확산 모델은 픽셀 공간에서 정의되지만, VAE나 GAN과 결합된 Latent Diffusion Models (LDM)의 경우 이 과정이 압축된 잠재 공간 $z$에서 일어난다. 1의 AAE가 잠재 공간의 분포를 정규화하는 데 탁월한 성능을 보였듯이, 잠재 공간에서의 확산 모델에 판별자 교정을 적용하면 더욱 효과적일 수 있다. 잠재 공간은 픽셀 공간보다 차원이 낮고 의미론적(Semantic) 정보가 밀집되어 있어, 판별자가 데이터의 구조적 결함을 더 잘 감지할 수 있기 때문이다. 이 경우 $x$ 대신 잠재 벡터 $z$에 대해 위 알고리즘을 적용하며, 판별자 또한 잠재 벡터를 입력으로 받도록 설계된다.

## **5\. 실험적 보강 방안 및 성능 검증 계획**

제안된 하이브리드 모델의 성능을 객관적으로 검증하기 위해, 기존 연구 1의 결과를 베이스라인으로 하는 구체적인 실험 설계를 제시한다.

### **5.1 데이터셋 및 평가 지표**

실험은 생성 모델의 표준 벤치마크인 \*\*CIFAR-10 ($32 \\times 32$)\*\*과 고해상도 생성 능력을 검증하기 위한 **CelebA-HQ ($256 \\times 256$, $1024 \\times 1024$)**, **LSUN ($256 \\times 256$)** 데이터셋을 사용한다.

* **FID (Fréchet Inception Distance):** 생성된 이미지와 실제 이미지 간의 분포 거리를 측정하여 품질과 다양성을 종합적으로 평가한다. 1의 SOTA 기록인 CIFAR-10 FID 2.20을 갱신하는 것을 목표로 한다.  
* **IS (Inception Score):** 생성된 이미지의 선명도와 다양성을 평가한다. 1의 9.89 이상을 목표로 한다.  
* **NLL (Negative Log-Likelihood):** Probability Flow ODE를 사용하여 정확한 우도(bits/dim)를 측정한다.1 판별자 교정이 분포의 꼬리(Tail) 부분 모델링을 개선하여 NLL을 낮추는지 확인한다 (목표: \< 2.99).  
* **NFE (Number of Function Evaluations):** 샘플 하나를 생성하는 데 필요한 네트워크 호출 횟수. 판별자 교정이 수렴 속도를 높여 NFE를 줄일 수 있는지 검증한다.

### **5.2 비교 실험 설계**

1. **베이스라인 비교:**  
   * **VE SDE (NCSN++):** 1에서 제안된 분산 발산형 모델.  
   * **VP SDE (DDPM++):** 1에서 제안된 분산 보존형 모델.  
   * **Proposed Hybrid SDE:** 위 두 모델의 샘플링 단계에 Discriminator-Guided Corrector를 적용한 모델. 판별자 네트워크 구조는 1의 NCSN++/DDPM++ 백본에 시간 임베딩을 추가한 U-Net 형태를 사용한다.  
2. **Ablation Study (구성 요소 분석):**  
   * **교정 강도 $\\gamma$의 영향:** $\\gamma=0$일 때는 기존 PC 샘플러와 동일하다. $\\gamma$를 점진적으로 증가시키며 FID와 Recall(다양성 지표)의 변화를 관찰한다. 과도한 $\\gamma$는 GAN의 모드 붕괴 특성을 야기할 수 있으므로 최적의 균형점을 찾는 것이 중요하다.  
   * **판별자 학습 시점:** 판별자를 스코어 네트워크와 동시에 학습(Joint Training)하는 경우와, 사전 학습된 스코어 네트워크에 대해 별도로 학습(Post-hoc Training)하는 경우를 비교한다. 본 제안은 기존 모델의 재학습 없이 샘플링 단계만 개선하는 Post-hoc 방식의 효율성을 강조한다.  
3. **저밀도 영역 탐색 분석 (Toy Experiment):**  
   * 1에서 사용된 2D Mixture of Gaussians 또는 Swiss Roll 데이터셋을 사용하여, 판별자 교정 유무에 따른 샘플링 궤적(Trajectory)을 시각화한다. 판별자 가이드가 적용되었을 때 궤적이 데이터 매니폴드(가우시안 모드 중심)로 더 빠르게 수렴하는지 정성적으로 확인한다.

### **5.3 고해상도 이미지 및 분포 이동(Distribution Shift) 분석**

1는 $1024 \\times 1024$ 해상도의 이미지 생성에 성공했으나, 고차원 공간에서의 스코어 추정은 여전히 어렵다. 특히 '차원의 저주'로 인해 고해상도 이미지의 전역적 일관성(Global Coherence)이 깨지는 경우가 발생한다. 판별자는 이미지의 전체적인 구조를 파악하는 데 강점이 있으므로, 고해상도 생성 실험에서 판별자 교정이 얼굴의 대칭성이나 배경의 일관성 등을 얼마나 개선하는지 분석한다.

또한, Probability Flow ODE를 활용한 잠재 공간 보간(Interpolation) 실험 1을 수행한다. 판별자 교정이 적용된 잠재 공간 경로가 기존 방식보다 더 부드럽고 의미론적으로 자연스러운 이미지 변화를 만들어내는지 검증한다. 이는 AAE 1가 보여준 잠재 공간의 매끄러운 탐색 능력이 확산 모델에서도 재현됨을 입증하는 것이다.

### **5.4 예상 결과 및 해석**

우리는 제안된 방법이 기존 SDE 기반 모델 대비 FID를 유의미하게 감소시킬 것으로 예상한다. 특히 스코어 네트워크가 놓치기 쉬운 미세한 텍스처나 구조적 결함을 판별자가 감지하여 수정함으로써 시각적 품질이 향상될 것이다. 또한, Corrector가 샘플을 매니폴드 쪽으로 강력하게 밀어주기 때문에, 더 적은 수의 Corrector 스텝(M)으로도 수렴이 가능해져 전체적인 샘플링 속도(NFE 감소)가 개선될 것으로 기대된다. 마지막으로, 우도(NLL) 측면에서도 판별자가 분포의 경계면을 명확히 하여 불필요한 확률 밀도의 확산을 막음으로써 더 정확한 모델링이 가능할 것이다.

## **6\. 결론 및 향후 연구 방향**

본 연구 보고서는 생성 모델링의 난제인 저밀도 영역에서의 샘플링 불안정성을 해결하기 위해, GAN의 판별자를 활용한 밀도 비율 추정 기반의 교정 방법론을 제안하였다. 확률 미분 방정식(SDE)이라는 견고한 수학적 토대 위에서, 판별자의 그래디언트가 스코어 함수의 편향을 보정하는 벡터장으로 작용함을 이론적으로 규명하였다. 또한, 이를 Predictor-Corrector 샘플러에 통합하여 실질적인 성능 향상을 이끌어낼 수 있는 구체적인 알고리즘과 실험 계획을 수립하였다.

이 하이브리드 접근법은 SDE가 제공하는 유연한 샘플링, 정확한 우도 계산, 역문제 해결 능력 1을 온전히 유지하면서도, GAN이 가진 높은 샘플 품질과 분포 매칭 능력을 결합한다는 점에서 큰 의의가 있다. 이는 단순히 두 모델을 섞는 것을 넘어, 각 모델의 약점(SDE의 저밀도 영역 오차, GAN의 모드 붕괴)을 상호 보완하는 시너지 효과를 창출한다.

향후 연구에서는 시간 의존적 판별자의 학습 안정성을 확보하기 위한 기법(예: Spectral Normalization, R1 Regularization)의 최적화와, 판별자 학습 비용을 최소화하기 위한 효율적인 아키텍처 탐색이 요구된다. 또한, 조건부 생성(Conditional Generation)이나 인페인팅(Inpainting)과 같은 다양한 응용 분야 1에서 판별자 가이드가 미치는 영향에 대한 심층적인 분석이 필요할 것이다. 본 연구가 제시하는 방향성은 차세대 생성 모델이 나아가야 할 '통합과 융합'의 길을 구체화하는 중요한 이정표가 될 것이다.

#### **참고 자료**

1. 02.Auto-Encoding Variational Bayes(VAE).pdf